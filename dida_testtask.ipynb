{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4ta7vPTNKz+1DOJxqvvEp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celaira/roof_deep_learning/blob/main/dida_testtask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mount google drive:"
      ],
      "metadata": {
        "id": "rJMyJrHot4J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XnQnolw4tvrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b391f229-c102-4de6-f99e-d3e48847f56a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import stuff"
      ],
      "metadata": {
        "id": "OPGsrPc69ld0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dZ8y2_wSttKD"
      },
      "outputs": [],
      "source": [
        "#import json\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, InputLayer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create path to data:"
      ],
      "metadata": {
        "id": "MB-ZFURR9pPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_image_path = '/content/drive/MyDrive/training_image'\n",
        "label_path = '/content/drive/MyDrive/label'\n",
        "test_image_path = '/content/drive/MyDrive/test_image'"
      ],
      "metadata": {
        "id": "UCKzdCwE9xJJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder))\n",
        "    for filename in filenames:\n",
        "        img = cv.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "train_image = np.array(load_images_from_folder(training_image_path))\n",
        "label = np.array(load_images_from_folder(label_path))\n",
        "test_image = np.array(load_images_from_folder(test_image_path))\n",
        "\n",
        "#normalization\n",
        "train_image = np.array(train_image) / 255.0\n",
        "label = np.array(label) / 255.0\n",
        "test_image = np.array(test_image) / 255.0"
      ],
      "metadata": {
        "id": "hoE0EhyeCyXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the images:"
      ],
      "metadata": {
        "id": "ma3w6Zp_NDnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder))\n",
        "    for filename in filenames:\n",
        "        img = cv.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return np.array(images), filenames\n",
        "\n",
        "train_images, train_image_filenames = load_images_from_folder(training_image_path)\n",
        "labels, label_filenames = load_images_from_folder(label_path)\n",
        "test_images, test_image_filenames = load_images_from_folder(test_image_path)\n",
        "\n",
        "# Ensure the training images and labels are aligned by sorting the filenames\n",
        "train_image_filenames_sorted = sorted(train_image_filenames)\n",
        "label_filenames_sorted = sorted(label_filenames)\n",
        "\n",
        "aligned_train_images = [cv.imread(os.path.join(training_image_path, filename)) for filename in train_image_filenames_sorted]\n",
        "aligned_labels = [cv.imread(os.path.join(label_path, filename), cv.IMREAD_GRAYSCALE) for filename in label_filenames_sorted]\n",
        "\n",
        "# Convert to numpy arrays\n",
        "aligned_train_images = np.array(aligned_train_images)\n",
        "aligned_labels = np.array(aligned_labels)\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "# Normalize the images\n",
        "aligned_train_images = aligned_train_images / 255.0\n",
        "aligned_labels = aligned_labels / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "KumvKEJMNDzw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#binarize the labels\n",
        "labels = np.where(labels > 0.5, 1, 0)\n",
        "\n",
        "#needed for keras -> need to look it up again\n",
        "train_images = train_images[..., np.newaxis]\n",
        "labels = labels[..., np.newaxis]\n",
        "test_images = test_images[..., np.newaxis]\n",
        "\n",
        "# split training and validation -> nicht ganz verstanden\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3zIpoN_dC9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating validation for better error-testing:"
      ],
      "metadata": {
        "id": "qD_6Yh2w-TkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels\n",
        "aligned_labels = np.where(aligned_labels > 0.5, 1, 0)\n",
        "\n",
        "# Add an extra dimension to the data\n",
        "aligned_train_images = aligned_train_images[..., np.newaxis]\n",
        "aligned_labels = aligned_labels[..., np.newaxis]\n",
        "test_images = test_images[..., np.newaxis]\n",
        "\n",
        "# Split training and validation data\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(aligned_train_images, aligned_labels, test_size=0.2, random_state=42)\n",
        "print(aligned_train_images.shape)"
      ],
      "metadata": {
        "id": "RX7W7HgkA5ZX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential model define (simple):"
      ],
      "metadata": {
        "id": "EmXz3QZw6qjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#Encodes\n",
        "model.add(InputLayer(input_shape=aligned_train_images.shape[1:]))\n",
        "print(aligned_train_images.shape)\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "# Decoder\n",
        "model.add(Conv2DTranspose(512, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(256, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(128, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(64, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Conv2D(1, (1, 1), activation='sigmoid'))"
      ],
      "metadata": {
        "id": "rXPHSz1Y6o5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model:"
      ],
      "metadata": {
        "id": "NCFOdW0ABKp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=5,\n",
        "                    validation_data=(val_images, val_labels))\n",
        "model.save('/content/drive/MyDrive/save')\n",
        "val_loss, val_acc = model.evaluate(val_images, val_labels)"
      ],
      "metadata": {
        "id": "FgEEjrQwBMTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions and Visualization of them :"
      ],
      "metadata": {
        "id": "JEyeCdv3BP5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)\n",
        "predictions_path = '/content/drive/MyDrive/predictions'\n",
        "os.makedirs(predictions_path, exist_ok=True)\n",
        "\n",
        "for i, pred in enumerate(predictions):\n",
        "    pred_mask = (pred.squeeze() * 255).astype(np.uint8)\n",
        "    cv.imwrite(os.path.join(predictions_path, f'prediction_{i}.png'), pred_mask)\n",
        "def display_predictions(test_images, predictions, num=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num):\n",
        "        plt.subplot(num, 3, i*3 + 1)\n",
        "        plt.imshow(test_images[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Test Image\")\n",
        "\n",
        "        plt.subplot(num, 3, i*3 + 2)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Prediction\")\n",
        "\n",
        "        plt.subplot(num, 3, i*3 + 3)\n",
        "        plt.imshow(test_images[i].squeeze(), cmap='gray')\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='jet', alpha=0.5)\n",
        "        plt.title(\"Overlay\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "display_predictions(test_images, predictions)"
      ],
      "metadata": {
        "id": "56JFb4ab7S1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a UNET-Model:**\n",
        "\n",
        "unet_model is a function that takes input_shape as an argument, which defines the shape of the input images (e.g., height, width, and number of channels).\n",
        "\n",
        "layers.Input creates a Keras tensor, which will act as the input layer of the model. The shape of this input is defined by input_shape."
      ],
      "metadata": {
        "id": "5POvkJOJAuUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    pass"
      ],
      "metadata": {
        "id": "-62pJlhUA0hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (train_images.shape[1], train_images.shape[2], train_images.shape[3])\n",
        "model = unet_model(input_shape)\n",
        "# Reshape the output layer to match the shape of the labels\n",
        "model.add(tf.keras.layers.Reshape((train_labels.shape[1], train_labels.shape[2], train_labels.shape[3])))\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.compile(optimizer='Adam'(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=8, validation_split=0.2)"
      ],
      "metadata": {
        "id": "xhzzOy9yBRkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}