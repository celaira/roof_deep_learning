{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlQRmg3YM1Hp5LQj0rl4LA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celaira/roof_deep_learning/blob/main/dida_testtask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Images:**"
      ],
      "metadata": {
        "id": "PPh7PSi0Q1NQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mount google drive:"
      ],
      "metadata": {
        "id": "rJMyJrHot4J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XnQnolw4tvrH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import stuff"
      ],
      "metadata": {
        "id": "OPGsrPc69ld0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dZ8y2_wSttKD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, InputLayer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create path to data:"
      ],
      "metadata": {
        "id": "MB-ZFURR9pPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_image_path = '/content/drive/MyDrive/training_image'\n",
        "label_path = '/content/drive/MyDrive/label'\n",
        "test_image_path = '/content/drive/MyDrive/test_image'"
      ],
      "metadata": {
        "id": "UCKzdCwE9xJJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import the images:"
      ],
      "metadata": {
        "id": "ma3w6Zp_NDnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder))\n",
        "    for filename in filenames:\n",
        "        img = cv.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return np.array(images), filenames\n",
        "\n",
        "train_images, train_image_filenames = load_images_from_folder(training_image_path)\n",
        "labels, label_filenames = load_images_from_folder(label_path)\n",
        "test_images, test_image_filenames = load_images_from_folder(test_image_path)\n",
        "\n",
        "# Ensure the training images and labels are aligned by sorting the filenames\n",
        "train_image_filenames_sorted = sorted(train_image_filenames)\n",
        "label_filenames_sorted = sorted(label_filenames)\n",
        "\n",
        "aligned_train_images = [cv.imread(os.path.join(training_image_path, filename)) for filename in train_image_filenames_sorted]\n",
        "aligned_labels = [cv.imread(os.path.join(label_path, filename), cv.IMREAD_GRAYSCALE) for filename in label_filenames_sorted]\n",
        "\n",
        "# Convert to numpy arrays\n",
        "aligned_train_images = np.array(aligned_train_images)\n",
        "aligned_labels = np.array(aligned_labels)\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "# Normalize the images\n",
        "aligned_train_images = aligned_train_images / 255.0\n",
        "aligned_labels = aligned_labels / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "KumvKEJMNDzw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating validation for better error-testing:"
      ],
      "metadata": {
        "id": "qD_6Yh2w-TkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels\n",
        "aligned_labels = np.where(aligned_labels > 0.5, 1, 0)\n",
        "\n",
        "# Add an extra dimension to the data\n",
        "aligned_train_images = aligned_train_images[..., np.newaxis]\n",
        "aligned_labels = aligned_labels[..., np.newaxis]\n",
        "test_images = test_images[..., np.newaxis]\n",
        "\n",
        "# Split training and validation data\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(aligned_train_images, aligned_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "RX7W7HgkA5ZX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a UNET-Model:**\n",
        "\n",
        "unet_model is a function that takes input_shape as an argument, which defines the shape of the input images (e.g., height, width, and number of channels).\n",
        "\n",
        "layers.Input creates a Keras tensor, which will act as the input layer of the model. The shape of this input is defined by input_shape."
      ],
      "metadata": {
        "id": "5POvkJOJAuUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the U-Net model\n",
        "def unet_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(2, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "-62pJlhUA0hX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model:**"
      ],
      "metadata": {
        "id": "NCFOdW0ABKp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (train_images.shape[1], train_images.shape[2], train_images.shape[3])\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "num_classes = 2  #2 classes: roof and non-roof\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
        "history = model.fit(train_images, train_labels_cat, epochs=20, batch_size=5, validation_data=(val_images, val_labels_cat))\n",
        "model.save('/content/drive/MyDrive/save')\n",
        "#val_loss, val_accuracy = model.evaluate(val_images, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk92AIkiLa0v",
        "outputId": "74812899-d515-4278-c967-c19ecd896b55"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 9s 449ms/step - loss: 1.9026 - accuracy: 0.8508 - val_loss: 0.4802 - val_accuracy: 0.8615\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.5391 - accuracy: 0.8527 - val_loss: 0.5883 - val_accuracy: 0.8615\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 1s 315ms/step - loss: 1.2579 - accuracy: 0.8527 - val_loss: 0.5331 - val_accuracy: 0.8615\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.5970 - accuracy: 0.8527 - val_loss: 0.6093 - val_accuracy: 0.8615\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.6138 - accuracy: 0.8527 - val_loss: 0.5941 - val_accuracy: 0.8615\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.5921 - accuracy: 0.8527 - val_loss: 0.5559 - val_accuracy: 0.8615\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.5492 - accuracy: 0.8527 - val_loss: 0.4905 - val_accuracy: 0.8615\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.4888 - accuracy: 0.8527 - val_loss: 0.4419 - val_accuracy: 0.8615\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 0.4692 - accuracy: 0.8527 - val_loss: 0.4483 - val_accuracy: 0.8615\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 0.4578 - accuracy: 0.8527 - val_loss: 0.4154 - val_accuracy: 0.8615\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.4280 - accuracy: 0.8527 - val_loss: 0.3985 - val_accuracy: 0.8615\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.4116 - accuracy: 0.8527 - val_loss: 0.3848 - val_accuracy: 0.8615\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.3907 - accuracy: 0.8527 - val_loss: 0.3884 - val_accuracy: 0.8615\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 1s 335ms/step - loss: 0.3860 - accuracy: 0.8527 - val_loss: 0.3681 - val_accuracy: 0.8615\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 1s 387ms/step - loss: 0.3742 - accuracy: 0.8527 - val_loss: 0.3686 - val_accuracy: 0.8615\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 1s 351ms/step - loss: 0.3636 - accuracy: 0.8527 - val_loss: 0.3630 - val_accuracy: 0.8655\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 1s 366ms/step - loss: 0.3518 - accuracy: 0.8584 - val_loss: 0.3522 - val_accuracy: 0.8717\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 1s 335ms/step - loss: 0.3325 - accuracy: 0.8707 - val_loss: 1.1660 - val_accuracy: 0.3236\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.5724 - accuracy: 0.7399 - val_loss: 0.3928 - val_accuracy: 0.8615\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 1s 315ms/step - loss: 0.3946 - accuracy: 0.8527 - val_loss: 0.3817 - val_accuracy: 0.8615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions and Visualization of them :**"
      ],
      "metadata": {
        "id": "JEyeCdv3BP5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)\n",
        "predictions_path = '/content/drive/MyDrive/predictions'\n",
        "os.makedirs(predictions_path, exist_ok=True)\n",
        "\n",
        "for i, pred in enumerate(predictions):\n",
        "    pred_mask = np.argmax(pred, axis=-1)\n",
        "    pred_mask = (pred.squeeze() * 255).astype(np.uint8)\n",
        "    cv.imwrite(os.path.join(predictions_path, f'prediction_{i}.png'), pred_mask)\n",
        "import matplotlib.pyplot as plt\n",
        "def display_predictions(test_images, predictions, num=5):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num):\n",
        "        plt.subplot(num, 3, i*3 + 1)\n",
        "        plt.imshow(test_images[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Test Image\")\n",
        "\n",
        "        plt.subplot(num, 3, i*3 + 2)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Prediction\")\n",
        "\n",
        "        plt.subplot(num, 3, i*3 + 3)\n",
        "        plt.imshow(test_images[i].squeeze(), cmap='gray')\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='jet', alpha=0.5)\n",
        "        plt.title(\"Overlay\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display predictions for the first 5 test images\n",
        "display_predictions(test_images, predictions, num=5)"
      ],
      "metadata": {
        "id": "56JFb4ab7S1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "3e4d90c3-74ef-437e-d553-d6194f5e7715"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 355ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:703: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-24167292ed7d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'prediction_{i}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:703: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRASH:**"
      ],
      "metadata": {
        "id": "tUF_51mTQcG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder))\n",
        "    for filename in filenames:\n",
        "        img = cv.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "train_image = np.array(load_images_from_folder(training_image_path))\n",
        "label = np.array(load_images_from_folder(label_path))\n",
        "test_image = np.array(load_images_from_folder(test_image_path))\n",
        "\n",
        "#normalization\n",
        "train_image = np.array(train_image) / 255.0\n",
        "label = np.array(label) / 255.0\n",
        "test_image = np.array(test_image) / 255.0"
      ],
      "metadata": {
        "id": "hoE0EhyeCyXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#binarize the labels\n",
        "labels = np.where(labels > 0.5, 1, 0)\n",
        "\n",
        "#needed for keras -> need to look it up again\n",
        "train_images = train_images[..., np.newaxis]\n",
        "labels = labels[..., np.newaxis]\n",
        "test_images = test_images[..., np.newaxis]\n",
        "\n",
        "# split training and validation -> nicht ganz verstanden\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3zIpoN_dC9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential model define (simple):"
      ],
      "metadata": {
        "id": "EmXz3QZw6qjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "#Encodes\n",
        "model.add(InputLayer(input_shape=aligned_train_images.shape[1:]))\n",
        "print(aligned_train_images.shape)\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "# Decoder\n",
        "model.add(Conv2DTranspose(512, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(256, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(128, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2DTranspose(64, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Conv2D(1, (1, 1), activation='sigmoid'))"
      ],
      "metadata": {
        "id": "rXPHSz1Y6o5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}